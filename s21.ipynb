{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347262ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from gpt import GPTLanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a8318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12eef6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b4efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(vocab_size)\n",
    "model.load_state_dict(torch.load('saved_model.pth'))\n",
    "m = model.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b38b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save the heaven doth using lawful time\n",
      "Stirr'd in the walls, senators on the wall!\n",
      "Ay, where speak frowards that sick hraven,\n",
      "As we do steph in Scotland be else?\n",
      "So far have been piled in Richard's death;\n",
      "And, Sir John Tlums, well--\n",
      "Alack-now for the county, mistren me mis--\n",
      "The not--tabes as years at once,--ball,\n",
      "Let's fault enough but done:--lot the nibat readment\n",
      "With all the wheet-bark-but, show'd, muls fond!\n",
      "Gold I bank thee, hoo, luckle bloody love!\n",
      "Ha! brike some, I'll kiss the world: do \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=cfg.device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a1462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf01a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
